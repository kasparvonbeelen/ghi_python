{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Corpus Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebooks provides you with various tools to explore and compare corpora in more detail. The techniques described here are especially powerful in combination the content of Notebook 5 **Corpus Creation**, especially when different subcorpora are compared and contrasted to each other.\n",
    "\n",
    "\n",
    "At the end of this Notebook\n",
    "\n",
    "More specifically we discuss:\n",
    "\n",
    "- Keyword in Context Analysis: Similar to concardance in AntConc.\n",
    "- Collocations: \n",
    "- Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Keyword in Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from pathlib import Path\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "moh_reports = list(Path('data/MOH/python').glob('*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/MOH/python/PoplarMetropolitanBorough.1945.b18246175.txt'),\n",
       " PosixPath('data/MOH/python/CityofWestminster.1932.b18247945.txt'),\n",
       " PosixPath('data/MOH/python/CityofWestminster.1921.b18247830.txt'),\n",
       " PosixPath('data/MOH/python/PoplarandBromley.1900.b18245754.txt'),\n",
       " PosixPath('data/MOH/python/Poplar.1919.b18120878.txt'),\n",
       " PosixPath('data/MOH/python/PoplarMetropolitanBorough.1920.b18245924.txt'),\n",
       " PosixPath('data/MOH/python/CityofWestminster.1907.b18247726.txt'),\n",
       " PosixPath('data/MOH/python/CityofWestminster.1906.b18247714.txt'),\n",
       " PosixPath('data/MOH/python/CityofWestminster.1903.b18247684.txt'),\n",
       " PosixPath('data/MOH/python/PoplarMetropolitanBorough.1902.b18245778.txt')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moh_reports[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75480fcb0964667b6a9e285229c9c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for r in tqdm(moh_reports):\n",
    "    with open(r) as in_doc:\n",
    "        \n",
    "        tokens = wordpunct_tokenize(in_doc.read().lower())\n",
    "        for token in tokens:\n",
    "            if token.isalpha():\n",
    "                corpus.append(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected 3550169 tokens\n"
     ]
    }
   ],
   "source": [
    "print('collected', len(corpus),'tokens')\n",
    "nltk_corpus = nltk.text.Text(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 1112 matches:\n",
      "lt to arrange but the friends of the poor and the charity organisation society\n",
      "in one case the milk proved to be of poor quality the work is carried out in t\n",
      "uality between per cent and per cent poor quality between per cent and per cen\n",
      "rict total good quality fair quality poor quality adulterated no percent no pe\n",
      "e applicant is already in receipt of poor law relief or is considered ought to\n",
      "reviously notified under to to total poor law institutions sanatoria poor law \n",
      "otal poor law institutions sanatoria poor law institutions sanatoria pulmonary\n",
      "ulosis and the treatment of cases in poor law and other hospitals advance in s\n",
      "the fat was between and per cent and poor or inferior quality in which the fat\n",
      " no per cent fair quality no percent poor quality no percent adulterated no pe\n",
      "er to to total primary notifications poor law institution sanatoria pulmonary \n",
      "er to to total primary notifications poor law institutions sanatoria pulmonary\n",
      "er to to total primary notifications poor law institutions sanatoria pulmonary\n",
      "er to to total primary notifications poor law institutions sanatoria pulmonary\n",
      "ions on form d cases discharged from poor law institutions and sanatoria popla\n",
      " sanatoria poplar bromley bow totals poor law institutions pulmonary m f nonpu\n",
      "er to to total primary notifications poor law institutions sanatoria pulmonary\n",
      "er to to total primary notifications poor law institutions sanatoria pulmonary\n",
      "er to to total primary notifications poor law institutions sanatoria pulmonary\n",
      "under to total primary notifications poor law institutions sanatoria pulmonary\n",
      "ions on form d cases discharged from poor law institutions and sanatoria poor \n",
      " poor law institutions and sanatoria poor law institutions pulmonary poplar br\n",
      "m of the london county council c the poor law infirmary d in a few cases in pa\n",
      "ex service men by application to the poor law guardians xi the arrangements fo\n",
      "on for advanced cases apart from the poor law infirmary the difficulty of find\n"
     ]
    }
   ],
   "source": [
    "nltk_corpus.concordance('poor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per cent; public health; county council; london county; medical\n",
      "officer; scarlet fever; whooping cough; males females; local\n",
      "government; legal proceedings; dwelling houses; poplar bromley; small\n",
      "pox; ice cream; sub district; government board; child welfare; city\n",
      "council; death rate; bromley bow\n"
     ]
    }
   ],
   "source": [
    "nltk_corpus.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abso', 'lutely'),\n",
       " ('acidi', 'lacfc'),\n",
       " ('acquires', 'setiological'),\n",
       " ('adolph', 'mussi'),\n",
       " ('adolphus', 'massie'),\n",
       " ('adultorated', 'sanples'),\n",
       " ('adver', 'tising'),\n",
       " ('aeql', 'rrhage'),\n",
       " ('alathilde', 'christoffersen'),\n",
       " ('alio', 'wances')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(nltk_corpus)\n",
    "finder.nbest(bigram_measures.pmi, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bowers', 'gifford'),\n",
       " ('carrie', 'simuelson'),\n",
       " ('culex', 'pipiens'),\n",
       " ('heatherfield', 'ascot'),\n",
       " ('holmes', 'godson'),\n",
       " ('lehman', 'ashmead'),\n",
       " ('locum', 'tenens'),\n",
       " ('nemine', 'contradicente'),\n",
       " ('quinton', 'polyclinic'),\n",
       " ('rhesus', 'incompatibility')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.apply_freq_filter(3)\n",
    "finder.nbest(bigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finder = BigramCollocationFinder.from_words(nltk_corpus, window_size = 20)\n",
    "# finder.apply_freq_filter(3)\n",
    "# finder.nbest(bigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apprenticing', 'poor'),\n",
       " ('poor', 'gentlewomen'),\n",
       " ('poor', 'lawinstitu'),\n",
       " ('qualitj', 'poor'),\n",
       " ('regulgtions', 'poor'),\n",
       " ('poor', 'attenders'),\n",
       " ('poor', 'palatines'),\n",
       " ('poor', 'genl'),\n",
       " ('poor', 'ffour'),\n",
       " ('poor', 'packaging')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder = BigramCollocationFinder.from_words(nltk_corpus)\n",
    "token_filter = lambda *w: 'poor' not in w\n",
    "finder.apply_ngram_filter(token_filter)\n",
    "finder.nbest(bigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on BigramAssocMeasures in module nltk.metrics.association object:\n",
      "\n",
      "class BigramAssocMeasures(NgramAssocMeasures)\n",
      " |  A collection of bigram association measures. Each association measure\n",
      " |  is provided as a function with three arguments::\n",
      " |  \n",
      " |      bigram_score_fn(n_ii, (n_ix, n_xi), n_xx)\n",
      " |  \n",
      " |  The arguments constitute the marginals of a contingency table, counting\n",
      " |  the occurrences of particular events in a corpus. The letter i in the\n",
      " |  suffix refers to the appearance of the word in question, while x indicates\n",
      " |  the appearance of any word. Thus, for example:\n",
      " |  \n",
      " |      n_ii counts (w1, w2), i.e. the bigram being scored\n",
      " |      n_ix counts (w1, *)\n",
      " |      n_xi counts (*, w2)\n",
      " |      n_xx counts (*, *), i.e. any bigram\n",
      " |  \n",
      " |  This may be shown with respect to a contingency table::\n",
      " |  \n",
      " |              w1    ~w1\n",
      " |           ------ ------\n",
      " |       w2 | n_ii | n_oi | = n_xi\n",
      " |           ------ ------\n",
      " |      ~w2 | n_io | n_oo |\n",
      " |           ------ ------\n",
      " |           = n_ix        TOTAL = n_xx\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      BigramAssocMeasures\n",
      " |      NgramAssocMeasures\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  chi_sq(n_ii, n_ix_xi_tuple, n_xx) from abc.ABCMeta\n",
      " |      Scores bigrams using chi-square, i.e. phi-sq multiplied by the number\n",
      " |      of bigrams, as in Manning and Schutze 5.3.3.\n",
      " |  \n",
      " |  fisher(*marginals) from abc.ABCMeta\n",
      " |      Scores bigrams using Fisher's Exact Test (Pedersen 1996).  Less\n",
      " |      sensitive to small counts than PMI or Chi Sq, but also more expensive\n",
      " |      to compute. Requires scipy.\n",
      " |  \n",
      " |  phi_sq(*marginals) from abc.ABCMeta\n",
      " |      Scores bigrams using phi-square, the square of the Pearson correlation\n",
      " |      coefficient.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  dice(n_ii, n_ix_xi_tuple, n_xx)\n",
      " |      Scores bigrams using Dice's coefficient.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from NgramAssocMeasures:\n",
      " |  \n",
      " |  jaccard(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams using the Jaccard index.\n",
      " |  \n",
      " |  likelihood_ratio(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams using likelihood ratios as in Manning and Schutze 5.3.4.\n",
      " |  \n",
      " |  pmi(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams by pointwise mutual information, as in Manning and\n",
      " |      Schutze 5.4.\n",
      " |  \n",
      " |  poisson_stirling(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams using the Poisson-Stirling measure.\n",
      " |  \n",
      " |  student_t(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams using Student's t test with independence hypothesis\n",
      " |      for unigrams, as in Manning and Schutze 5.3.1.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from NgramAssocMeasures:\n",
      " |  \n",
      " |  mi_like(*marginals, **kwargs)\n",
      " |      Scores ngrams using a variant of mutual information. The keyword\n",
      " |      argument power sets an exponent (default 3) for the numerator. No\n",
      " |      logarithm of the result is calculated.\n",
      " |  \n",
      " |  raw_freq(*marginals)\n",
      " |      Scores ngrams by their frequency\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from NgramAssocMeasures:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bigram_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57850c0d978b4afaaf2218187aac45d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "corpus = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for r in tqdm(moh_reports):\n",
    "    with open(r) as in_doc:\n",
    "        if 'westminster' in r.name.lower():\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "\n",
    "        corpus.append(in_doc.read().lower())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 159\n"
     ]
    }
   ],
   "source": [
    "print(len(labels),len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=5)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2 = SelectKBest(chi2, k=10)\n",
    "X = ch2.fit_transform(X, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('borough', 6827.175533272762),\n",
       " ('bow', 6681.346216439548),\n",
       " ('bromley', 6861.134136366376),\n",
       " ('city', 4592.729181914567),\n",
       " ('east', 1499.0376786761663),\n",
       " ('poplar', 11888.857471790638),\n",
       " ('road', 8510.875738951223),\n",
       " ('see', 2314.6724275246893),\n",
       " ('street', 4330.436649540313),\n",
       " ('westminster', 5105.364636488248)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected = [(feature_names[i],ch2.scores_[i])for i\n",
    "                    in ch2.get_support(indices=True)]\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TextFeatureSelection\n",
      "  Downloading https://files.pythonhosted.org/packages/42/3d/351dcabf4198218a4b7421e6f6069eb089af6f5642e8fdd5d95f11904726/TextFeatureSelection-0.0.12-py3-none-any.whl\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (from TextFeatureSelection) (0.22.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (from TextFeatureSelection) (0.25.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from TextFeatureSelection) (1.17.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn->TextFeatureSelection) (0.13.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn->TextFeatureSelection) (1.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/site-packages (from pandas->TextFeatureSelection) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas->TextFeatureSelection) (2018.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->TextFeatureSelection) (1.11.0)\n",
      "Installing collected packages: TextFeatureSelection\n",
      "Successfully installed TextFeatureSelection-0.0.12\n"
     ]
    }
   ],
   "source": [
    "!pip3 install TextFeatureSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word list</th>\n",
       "      <th>word occurence count</th>\n",
       "      <th>Proportional Difference</th>\n",
       "      <th>Mutual Information</th>\n",
       "      <th>Chi Square</th>\n",
       "      <th>Information Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>103</td>\n",
       "      <td>-0.009709</td>\n",
       "      <td>0.094959</td>\n",
       "      <td>2.463282</td>\n",
       "      <td>0.004326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000</td>\n",
       "      <td>149</td>\n",
       "      <td>0.073826</td>\n",
       "      <td>0.008605</td>\n",
       "      <td>0.150191</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>1.185538</td>\n",
       "      <td>0.001507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>2.595483</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>000163</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.854210</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42232</td>\n",
       "      <td>¾gallons</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>1.185538</td>\n",
       "      <td>0.001507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42233</td>\n",
       "      <td>¾ths</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>1.185538</td>\n",
       "      <td>0.001507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42234</td>\n",
       "      <td>ægis</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.854210</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42235</td>\n",
       "      <td>æration</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>1.185538</td>\n",
       "      <td>0.001507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42236</td>\n",
       "      <td>œsophagus</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>1.185538</td>\n",
       "      <td>0.001507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42237 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word list  word occurence count  Proportional Difference  \\\n",
       "0             00                   103                -0.009709   \n",
       "1            000                   149                 0.073826   \n",
       "2         000000                     1                -1.000000   \n",
       "3           0001                     3                 1.000000   \n",
       "4         000163                     1                 1.000000   \n",
       "...          ...                   ...                      ...   \n",
       "42232   ¾gallons                     1                -1.000000   \n",
       "42233       ¾ths                     1                -1.000000   \n",
       "42234       ægis                     1                 1.000000   \n",
       "42235    æration                     1                -1.000000   \n",
       "42236  œsophagus                     1                -1.000000   \n",
       "\n",
       "       Mutual Information  Chi Square  Information Gain  \n",
       "0                0.094959    2.463282          0.004326  \n",
       "1                0.008605    0.150191          0.000266  \n",
       "2                0.778445    1.185538          0.001507  \n",
       "3                    -inf    2.595483          0.000000  \n",
       "4                    -inf    0.854210          0.000000  \n",
       "...                   ...         ...               ...  \n",
       "42232            0.778445    1.185538          0.001507  \n",
       "42233            0.778445    1.185538          0.001507  \n",
       "42234                -inf    0.854210          0.000000  \n",
       "42235            0.778445    1.185538          0.001507  \n",
       "42236            0.778445    1.185538          0.001507  \n",
       "\n",
       "[42237 rows x 6 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from TextFeatureSelection import TextFeatureSelection\n",
    "fsOBJ=TextFeatureSelection(target=labels,input_doc_list=corpus)\n",
    "result_df=fsOBJ.getScore()\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word list</th>\n",
       "      <th>word occurence count</th>\n",
       "      <th>Proportional Difference</th>\n",
       "      <th>Mutual Information</th>\n",
       "      <th>Chi Square</th>\n",
       "      <th>Information Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30606</td>\n",
       "      <td>pop</td>\n",
       "      <td>59</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>110.515890</td>\n",
       "      <td>0.184282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9432</td>\n",
       "      <td>bow</td>\n",
       "      <td>89</td>\n",
       "      <td>-0.640449</td>\n",
       "      <td>0.580268</td>\n",
       "      <td>106.152339</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21070</td>\n",
       "      <td>horseferry</td>\n",
       "      <td>71</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>-3.484235</td>\n",
       "      <td>102.313762</td>\n",
       "      <td>0.239720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8788</td>\n",
       "      <td>bessborough</td>\n",
       "      <td>67</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>98.289813</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42219</td>\n",
       "      <td>zymotic</td>\n",
       "      <td>94</td>\n",
       "      <td>-0.553191</td>\n",
       "      <td>0.525609</td>\n",
       "      <td>93.326942</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26433</td>\n",
       "      <td>millbank</td>\n",
       "      <td>62</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>86.266363</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15282</td>\n",
       "      <td>dock</td>\n",
       "      <td>66</td>\n",
       "      <td>-0.787879</td>\n",
       "      <td>0.666327</td>\n",
       "      <td>85.911216</td>\n",
       "      <td>0.149069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41176</td>\n",
       "      <td>wes</td>\n",
       "      <td>64</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>-3.380438</td>\n",
       "      <td>84.840438</td>\n",
       "      <td>0.205713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22037</td>\n",
       "      <td>india</td>\n",
       "      <td>67</td>\n",
       "      <td>-0.761194</td>\n",
       "      <td>0.651290</td>\n",
       "      <td>82.833472</td>\n",
       "      <td>0.144441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30188</td>\n",
       "      <td>pimlico</td>\n",
       "      <td>63</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>-3.364690</td>\n",
       "      <td>82.552451</td>\n",
       "      <td>0.201071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18111</td>\n",
       "      <td>fines</td>\n",
       "      <td>91</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>-1.093357</td>\n",
       "      <td>79.850990</td>\n",
       "      <td>0.139906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31245</td>\n",
       "      <td>procured</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>0.624294</td>\n",
       "      <td>79.780218</td>\n",
       "      <td>0.141947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14529</td>\n",
       "      <td>devons</td>\n",
       "      <td>47</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>78.605431</td>\n",
       "      <td>0.118591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26460</td>\n",
       "      <td>millwall</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.959184</td>\n",
       "      <td>0.757825</td>\n",
       "      <td>77.262501</td>\n",
       "      <td>0.118218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33936</td>\n",
       "      <td>ruston</td>\n",
       "      <td>46</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>76.252152</td>\n",
       "      <td>0.114306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17897</td>\n",
       "      <td>ferry</td>\n",
       "      <td>68</td>\n",
       "      <td>-0.705882</td>\n",
       "      <td>0.619380</td>\n",
       "      <td>74.205624</td>\n",
       "      <td>0.129299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24601</td>\n",
       "      <td>limehouse</td>\n",
       "      <td>45</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>73.940159</td>\n",
       "      <td>0.110155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11484</td>\n",
       "      <td>cleansings</td>\n",
       "      <td>45</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>73.940159</td>\n",
       "      <td>0.110155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7989</td>\n",
       "      <td>await</td>\n",
       "      <td>64</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>-2.281826</td>\n",
       "      <td>73.305433</td>\n",
       "      <td>0.165213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34547</td>\n",
       "      <td>seamen</td>\n",
       "      <td>65</td>\n",
       "      <td>-0.723077</td>\n",
       "      <td>0.629409</td>\n",
       "      <td>71.698892</td>\n",
       "      <td>0.122070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word list  word occurence count  Proportional Difference  \\\n",
       "30606          pop                    59                -1.000000   \n",
       "9432           bow                    89                -0.640449   \n",
       "21070   horseferry                    71                 0.971831   \n",
       "8788   bessborough                    67                 1.000000   \n",
       "42219      zymotic                    94                -0.553191   \n",
       "26433     millbank                    62                 1.000000   \n",
       "15282         dock                    66                -0.787879   \n",
       "41176          wes                    64                 0.968750   \n",
       "22037        india                    67                -0.761194   \n",
       "30188      pimlico                    63                 0.968254   \n",
       "18111        fines                    91                 0.692308   \n",
       "31245     procured                    70                -0.714286   \n",
       "14529       devons                    47                -1.000000   \n",
       "26460     millwall                    49                -0.959184   \n",
       "33936       ruston                    46                -1.000000   \n",
       "17897        ferry                    68                -0.705882   \n",
       "24601    limehouse                    45                -1.000000   \n",
       "11484   cleansings                    45                -1.000000   \n",
       "7989         await                    64                 0.906250   \n",
       "34547       seamen                    65                -0.723077   \n",
       "\n",
       "       Mutual Information  Chi Square  Information Gain  \n",
       "30606            0.778445  110.515890          0.184282  \n",
       "9432             0.580268  106.152339          0.000000  \n",
       "21070           -3.484235  102.313762          0.239720  \n",
       "8788                 -inf   98.289813          0.000000  \n",
       "42219            0.525609   93.326942          0.000000  \n",
       "26433                -inf   86.266363          0.000000  \n",
       "15282            0.666327   85.911216          0.149069  \n",
       "41176           -3.380438   84.840438          0.205713  \n",
       "22037            0.651290   82.833472          0.144441  \n",
       "30188           -3.364690   82.552451          0.201071  \n",
       "18111           -1.093357   79.850990          0.139906  \n",
       "31245            0.624294   79.780218          0.141947  \n",
       "14529            0.778445   78.605431          0.118591  \n",
       "26460            0.757825   77.262501          0.118218  \n",
       "33936            0.778445   76.252152          0.114306  \n",
       "17897            0.619380   74.205624          0.129299  \n",
       "24601            0.778445   73.940159          0.110155  \n",
       "11484            0.778445   73.940159          0.110155  \n",
       "7989            -2.281826   73.305433          0.165213  \n",
       "34547            0.629409   71.698892          0.122070  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df['word occurence count'] > 5].sort_values('Chi Square',ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method sort_values in module pandas.core.frame:\n",
      "\n",
      "sort_values(by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last') method of pandas.core.frame.DataFrame instance\n",
      "    Sort by the values along either axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "            by : str or list of str\n",
      "                Name or list of names to sort by.\n",
      "    \n",
      "                - if `axis` is 0 or `'index'` then `by` may contain index\n",
      "                  levels and/or column labels\n",
      "                - if `axis` is 1 or `'columns'` then `by` may contain column\n",
      "                  levels and/or index labels\n",
      "    \n",
      "                .. versionchanged:: 0.23.0\n",
      "                   Allow specifying index or column level names.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "         Axis to be sorted.\n",
      "    ascending : bool or list of bool, default True\n",
      "         Sort ascending vs. descending. Specify list for multiple sort\n",
      "         orders.  If this is a list of bools, must match the length of\n",
      "         the by.\n",
      "    inplace : bool, default False\n",
      "         If True, perform operation in-place.\n",
      "    kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      "         Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      "         information.  `mergesort` is the only stable algorithm. For\n",
      "         DataFrames, this option is only applied when sorting on a single\n",
      "         column or label.\n",
      "    na_position : {'first', 'last'}, default 'last'\n",
      "         Puts NaNs at the beginning if `first`; `last` puts NaNs at the\n",
      "         end.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    sorted_obj : DataFrame or None\n",
      "        DataFrame with sorted values if inplace=False, None otherwise.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({\n",
      "    ...     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      "    ...     'col2': [2, 1, 9, 8, 7, 4],\n",
      "    ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      "    ... })\n",
      "    >>> df\n",
      "        col1 col2 col3\n",
      "    0   A    2    0\n",
      "    1   A    1    1\n",
      "    2   B    9    9\n",
      "    3   NaN  8    4\n",
      "    4   D    7    2\n",
      "    5   C    4    3\n",
      "    \n",
      "    Sort by col1\n",
      "    \n",
      "    >>> df.sort_values(by=['col1'])\n",
      "        col1 col2 col3\n",
      "    0   A    2    0\n",
      "    1   A    1    1\n",
      "    2   B    9    9\n",
      "    5   C    4    3\n",
      "    4   D    7    2\n",
      "    3   NaN  8    4\n",
      "    \n",
      "    Sort by multiple columns\n",
      "    \n",
      "    >>> df.sort_values(by=['col1', 'col2'])\n",
      "        col1 col2 col3\n",
      "    1   A    1    1\n",
      "    0   A    2    0\n",
      "    2   B    9    9\n",
      "    5   C    4    3\n",
      "    4   D    7    2\n",
      "    3   NaN  8    4\n",
      "    \n",
      "    Sort Descending\n",
      "    \n",
      "    >>> df.sort_values(by='col1', ascending=False)\n",
      "        col1 col2 col3\n",
      "    4   D    7    2\n",
      "    5   C    4    3\n",
      "    2   B    9    9\n",
      "    0   A    2    0\n",
      "    1   A    1    1\n",
      "    3   NaN  8    4\n",
      "    \n",
      "    Putting NAs first\n",
      "    \n",
      "    >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      "        col1 col2 col3\n",
      "    3   NaN  8    4\n",
      "    4   D    7    2\n",
      "    5   C    4    3\n",
      "    2   B    9    9\n",
      "    0   A    2    0\n",
      "    1   A    1    1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(result_df.sort_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
