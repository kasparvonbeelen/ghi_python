{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kasparvonbeelen/ghi_python/blob/main/5%20-%20Corpus%20Selection.ipynb)\n",
    "\n",
    "# 5 Corpus Selection\n",
    "\n",
    "\n",
    "## Text Mining for Historians (with Python)\n",
    "## A Gentle Introduction to Working with Textual Data in Python\n",
    "\n",
    "### Created by Kaspar Beelen and Luke Blaxill\n",
    "\n",
    "### For the German Historical Institute, London\n",
    "\n",
    "<img align=\"left\" src=\"https://www.ghil.ac.uk/typo3conf/ext/wacon_ghil/Resources/Public/Images/institute_icon_small.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 5.1 Introduction\n",
    "\n",
    "When confronted with large collections of text, being able to find and select the relevant documents is a crucial skill for the digital historian.\n",
    "\n",
    "Selecting information from digital archives is a critical part of the research process. In this Notebook, we demonstrate various procedures for creating meaningful subsamples from a large collection of text (i.e. more relevant for a particular research question). \n",
    "\n",
    "For both the digital and analogue, corpus creation, finding those documents the possible merit closer inspection, is the first step. \n",
    "By selecting and filtering data, we can bring together otherwise disparate elements in one subcorpus.\n",
    "\n",
    "In most scenarios filtering documents is based on a combination of **metadata** and **content** criteria:\n",
    "- Metadata criteria: this involves electing documents that fall within a certain date range, or are produced in a specific geography, or by a political party. Such information is often encoded in the document metadata in our case studies, we will mainly use the filenames as metadata. \n",
    "- Content criteria: this involves selecting documents based on the words they contain. In this Notebook, we have a look at regular expressions, a powerful query technique that allows you to select documents based on complex patterns. We won't have time to go into details but discuss a relevant example in which you query multiple tokens at once.\n",
    "\n",
    "\n",
    "At the end of this Notebook, you'll be able to:\n",
    "- Iterate over a collection of files\n",
    "- Create a control flow `if else` for selecting documents\n",
    "- Write simple functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Unit of Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we create a subcorpora, we have to define the units of our collection, should these whole documents, paragraphs, sentences or even ngrams?\n",
    "\n",
    "For studying specific keywords we don't require the whole document, and sentences would suffice. In other words: what contexts do we want to include for our analysis? This depends on the question of course and we will explore different scenarios.\n",
    "\n",
    "For example, you could approximately split a text into paragraphs splitting a string on hard returns (two hard returns).\n",
    "\n",
    "In this cell we download \"Oliver Twist\" from gutenberg.org and get the text from the first sentence onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "text  = requests.get('https://www.gutenberg.org/files/730/730-0.txt').content.decode('utf-8') # get oliver twist\n",
    "content = text.split(' CHAPTER I.')[1] # get the string from the first sentence onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content[:2000] # print the first 2000 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the special characters in the string, you'll notice the sequence **\"\\r\\n\\r\\n\"** marking the boundary between paragraphs (approximately). We use this sequence to split `text` and store the result in `paragraphs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = content.split('\\r\\n\\r\\n')\n",
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paragraphs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to split a text into **sentences**. You can use the NLTK function `sent_tokenize`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(content)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or rely on SpaCy. Running the cell below could take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") # Load English model\n",
    "doc = nlp(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for s in doc.sents:\n",
    "    sentences.append(s)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Exercise\n",
    "\n",
    "Download another book from gutenburg.org (search for any book, select the \"Plain Text UTF-8\" version and use URL as a string in `requests.get`. The compute the average number of sentences per paragraph (i.e. count the number of paragraphs and divide this by the number of sentences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Exercise\n",
    "\n",
    "What is the average sentence lengths (in tokens) of Oliver Twist (i.e. divide the number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Exercise\n",
    "\n",
    "What is the length of the longest sentence in Oliver Twist? \n",
    "\n",
    "Tip: \n",
    "- Create an empty list\n",
    "- Iterate over the sentences and append the sentence length (with len) to the this list.\n",
    "- apply `max()` to this list, this will return the maximum value in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Filtering Based on Metadata\n",
    "\n",
    "After selecting the textual unit of our corpus, we proceed with defining other criteria for data selection. Here we focus on aspects related to the document's metadata, especially filtering by time.\n",
    "\n",
    "In the examples, we use articles from Heritage Made Digital newspapers. Please note that this corpus is already a sample (because the whole dataset was too large to share). We selected articles containing the word **\"slavery\"**. The exercises below demonstrate different techniques that enable you to create subsamples that zoom in specific periods and newspapers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Paths\n",
    "\n",
    "First, we show how to exploit information encoded in file names as metadata and use it for filtering documents; then we have a closer look at XML documents where metadata appears in the document's markup.\n",
    "\n",
    "**[Important]** Please run the following cells, which download and extract the data needed in the remainder of the Notebook. If you are using Colab and you need to restart the Kernel/Runtime (or it restarted by itself), please run these cells again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir working_data\n",
    "!mkdir working_data/hmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O working_data/aricles.zip https://github.com/kasparvonbeelen/ghi_python/raw/main/data/hmd_data/articles.zip\n",
    "!unzip -o working_data/aricles.zip -d working_data/hmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an external libary `pathlib` to make working with files and directories a bit easier.  \n",
    "\n",
    "We need to import `Path` object form this library first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, let's inspect where (and how) the articles are stored. We use the bash command `ls .` to list all documents in the current directory. To differentiate between bash and Python code, the former always start with an exclamation mark!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we list all folders in `working_dta/hmd`. Each newspaper in the collection has each folder. The names are  (NLP) IDs:\n",
    "\n",
    "- **0002088**: Liverpool standard and general commercial advertiser\n",
    "- **0002194**: The Sun (London) \n",
    "- **0002643**: The British Press; or, Morning Literary Advertiser\n",
    "- **0002644**: National Register\n",
    "- **0002646**: The Star\n",
    "- **0002647**: The Statesman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls working_data/hmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below lists all files in `0002644` (**National Register**). You'll notice that filenames have a particular structure. The `_` separate different parts of metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls working_data/hmd/0002644"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `pathlib` we can collect paths to all the files in our HMD collection. The code below may look a bit obscure at first but (explained in human language) it does the following:\n",
    "- define the location where the data are stored (path is provided as a string)\n",
    "- convert the string to a `Path` object, this allows us to use the functions and methods provided by the `pathlib` library\n",
    "- we apply `.glob()` to the `Path` object, this returns the path to all files that match a specific query pattern. We `\"**/*.txt\"` as query, this will find all `.txt` files that are descendant of `hmd` in `working_data`. See the folder structure below:\n",
    "```\n",
    "working_data\n",
    "|___ hmd\n",
    "\t|___ 0002643\n",
    "\t|        |__ 0002643_18030128_art0012.txt\n",
    "\t|        |__ ...\n",
    "\t|\n",
    "\t|___ 0002194\n",
    "\t|        |__ ...\n",
    "\t|___ ....\n",
    "```\n",
    "- Lastly, we convert the output of `.glob()` to a list (this for a minor technical reason we don't have to discuss this now) and print the number of paths we collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_hmd = Path('working_data/hmd') # tell where data is stored and return a Path object\n",
    "path_to_files = path_to_hmd.glob(\"**/*.txt\") # find all .txt files saved in working_data/hmd\n",
    "path_to_files = list(path_to_files) # convert generator to list\n",
    "len(path_to_files) # print number of paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could write this more concisely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files = list(Path('working_data/hmd').glob(\"**/*.txt\"))\n",
    "len(path_to_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the path to the first file in our collection (and the `.stem` attribute, i.e. the actual file name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_first_file = path_to_files[0] # get the path to the first file\n",
    "print(path_to_first_file) # print the path of path_to_first_file\n",
    "print(type(path_to_first_file)) # print the data type of path_to_first_file\n",
    "print(path_to_first_file.stem) # print the file name of path_to_first_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the file names follow a pattern `{newspaper ID}_{date}_{article ID}`. We can use this information to filter articles by date. In the scenario below, we want to select only those articles published between the 1st of January and the 25th of March 1807, to inspect the press coverage in the months before the Abolition Act received royal assent. We first show how to apply a filter to one file, but scaling up tho the whole collection is straightforward. \n",
    "\n",
    "We take a random path as the working example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_path = path_to_files[100] # select a pathname \n",
    "print(example_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this path, we get the `.stem` attribute ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = example_path.stem\n",
    "file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and use `str.split()` to get the individual components of the file name as a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name.split('_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The date appears in the second position, but remember that in Python we start counting from 0. To fetch the date from the list we need to use `[1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = file_name.split('_')[1] # split file name by _ and get second element in the resulting list\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first four characters of the `date` string refer to the year of publication. We can select those characters using slice notation, i.e. `[:4]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_str = date[:4] # get first four characters\n",
    "print(year_str, type(year_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step, we convert the string to an integer (this is called typecasting in Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = int(year_str) # convert string to integer\n",
    "print(year, type(year)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can put everything together and make the code more elegant by making use of multiple assignment (see example below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = '1_2_3'\n",
    "print(t.split(\"_\"))\n",
    "one, two, three = t.split(\"_\")\n",
    "print(one, two, three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_path = path_to_files[100] # select a pathname \n",
    "newspaper_id, date, art_id = example_path.stem.split(\"_\")\n",
    "print(newspaper_id, date, art_id)\n",
    "year,month,day = int(date[:4]),int(date[4:6]),int(date[6:])\n",
    "print(year,month,day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extracted different elements from the file name and parsed the date string, we can convert it to a proper Python time-stamp (i.e. a `datetime` object.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "ts_1 = datetime(year,month,day) # create datetime object from integers representing year, month and day\n",
    "ts_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows is to compare to dates, for example to check if one date is earlier or later target date. For this we can use `>` (bigger than) and `<` (smaller than) operators.\n",
    "\n",
    "`<` and `>` are **boolean** operators, as they return a `True` or `False` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_2 = datetime(1821,7,1)\n",
    "print(ts_2 > ts_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another boolean operator we'll encounter later on is the **equal to** operator (`==`).\n",
    "\n",
    "Please note that this is different then an assignment statement, which only uses one `=`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'Hello World' # assing x to the string \"Hello World\"\n",
    "print(x == 'Hello World') # check for equality, this should return True\n",
    "print(x == 'Hello World!') # check for equality, this should return False because of the ! at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if two dates are equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_1 = datetime(1821,7,1)\n",
    "ts_2 = datetime(1821,7,1)\n",
    "ts_1 == ts_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we test for a range, i.e. test if a time-stamp falls within a particular date range.\n",
    "We first decide on the lower and upper boundary and test if a `target_date` falls within the selected period (i.e. is greater than the lower boundary and smaller than the upper boundary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_b = datetime(1807,1,1)\n",
    "upper_b = datetime(1807,3,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = datetime(1807,2,15)\n",
    "lower_b < target_date < upper_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = datetime(1806,2,15)\n",
    "lower_b < target_date < upper_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = datetime(1808,2,15)\n",
    "lower_b < target_date < upper_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Breakout`:\n",
    "- [Boolean operators](break_out/conditions.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can package these steps in together in one function, the takes a path, upper and lower boundary are arguments, and returns a boolean (i.eWe can package these steps together in one function, which takes a path, an upper and a lower boundary are arguments, and returns a boolean value (i.e. `True` or `False`).\n",
    "\n",
    "Functions are ideal to group several statements (that you need repeatedly) and give them a name. Below we reuse the previous code for converting a path to a date, and evaluate if it falls within the date range set by the lower and upper boundary. We give this sequence of operations the name `in_daterange`. For each path in our collection, can call the function `in_daterange` to check if we should select it for our subsample.\n",
    "\n",
    "Don't forget to run the code cell below, otherwise, you won't be able to use the `in_daterange()` function.. `True` or `False`) value. \n",
    "\n",
    "Don't forget to run the code cell below, otherwise you won't be able to use the `in_daterange()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Breakout`:\n",
    "- [Functions](break_out/functions.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_daterange(path,lower_b,upper_b):\n",
    "    newspaper_id, date, art_id = path.stem.split(\"_\")\n",
    "    year,month,day = int(date[:4]),int(date[4:6]),int(date[6:])\n",
    "    target_date = datetime(year,month,day)\n",
    "    return lower_b < target_date < upper_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying the function to whole collection of paths, we test it on a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_b = datetime(1807,1,1)\n",
    "upper_b = datetime(1807,3,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files[700]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path_to_files[100]  \n",
    "print(path)\n",
    "in_daterange(path,lower_b,upper_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are almost ready to iterate over the whole corpus. We only need to discuss one more element of the Python syntax: the conditions. With the `for` loop you can iterate over a corpus, but we'd like to have a bit more control by for example treating documents inside our date range differently than others. \n",
    "\n",
    "Conditional statements are helpful here. We only have a closer look at the simplest form the 'if else ` statements. The following mock code shows how this works in Python\n",
    "\n",
    "```\n",
    "if condition is True:\n",
    "\texecute code\n",
    "else:\n",
    "\texecute code\n",
    "```\n",
    "Just one practical example will make this more understandable. We write a program the check is a number is greater than 10. Change the variable `i` to see how the program changes it behaviour depedending on wether the condition evaluates to `True` or `False`. In this case we use the greater or smaller than operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(4 > 10)\n",
    "print(100 > 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note the use of indentation (when a line ends with a colon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "if i > 10: # check if i is larger than 10, this will\n",
    "    print(i,f'is bigger than 10 because {i} > 10 evaluates to', i > 10)\n",
    "else:\n",
    "    print(f'{i} is smaller than 10. {i} > 10 evaluates to ', i > 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The breakout will provide a bit more information about `if else`, at this point please remember that when the code following the `if` evaluates to True, we will execute the code in the next line, other we skip this part and go straight to the else statements.\n",
    "\n",
    "Please remember that the function we wrote earlier `in_daterange` also returns a boolean value. In the small program below, \n",
    "- create an empty list where store the paths that match the conditions defined in line 6\n",
    "- we iterate over all paths and check if the date of the article matches the period we defined by setting a lower and upper boundary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_b = datetime(1807,1,1) # create start date of target period\n",
    "upper_b = datetime(1807,3,15) # create end date of target period\n",
    "\n",
    "selected_paths = [] # create a new variable referring to an empty list\n",
    "for p in path_to_files: # iterate over all the paths\n",
    "    if in_daterange(p,lower_b,upper_b): # check if the date of the article is within the boundaries of the target period\n",
    "        selected_paths.append(p) # if the above evaluates to True, append this path to the list\n",
    "    else: # else...\n",
    "        pass # ... do nothing\n",
    "print(len(selected_paths)) # print the number of selected paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want, you could continue with close reading these articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(open(selected_paths[1]).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Breakout`:\n",
    "- [Conditions and control flow](break_out/conditions.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --Exercise\n",
    "\n",
    "other date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --Exercise\n",
    "\n",
    "Other corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 XML\n",
    "\n",
    "**[Under construction]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Filtering based on Content\n",
    "\n",
    "Let's now explore techniques for selecting articles based on their content. We will touch on a new topic (but only in passing): regular expression, a rich query language that enables you to search for complex textual patterns. It is outside the scope of this tutorial to discuss regular expressions in-depth, but we show a useful example that allows you to search for multiple words at once. \n",
    "\n",
    "We'd like to know the extent to which articles discussing slavery make mention of political concepts, such as \"freedom\" and \"democracy\".\n",
    "\n",
    "Using regular expression often follows this procedure:\n",
    "- import re module (line 1) (only once suffices)\n",
    "- define pattern (line 2)\n",
    "- compile pattern (line 3)\n",
    "- apply the pattern to string (line 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # import re module\n",
    "pattern = r'\\bfreedom\\b|\\bdemocracy\\b' # define pattern, search for word freedom and democracy\n",
    "query = re.compile(pattern) # compile this pattern\n",
    "query.findall('Can there be freedom without democracy?') # apply the pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll skip the technicalities, since there are many excellent introductions regular expressions (the [NLTK handbook](https://www.nltk.org/book/ch03.html) is a good starting point) but we can explain the some of the syntax here, so you can adapt the code to other queries of interest.\n",
    "\n",
    "- `|`: 'OR' seperator \n",
    "- `\\b` word boundary\n",
    "\n",
    "If we remove the word boundary character, our query become more inclusive, it will also substrings. For example, the code below still matches the word \"democracy\", even though it only appears as a substring of \"ddemocracys\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\bfreedom\\b|democracy'\n",
    "query = re.compile(pattern)\n",
    "query.findall('can there be dfreedom, without ddemocracys?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily extend the query with the `OR` separator. Below we search for the tokens \"freedom\", \"democracy\" and words starting with the substring \"equal\".\n",
    "Please notice \n",
    "- the word boundary only appears at the left-hand side of \"equal\"\n",
    "- this may match more words than you'd think, both equality and equal, so be careful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\bfreedom\\b|\\bdemocracy\\b|\\bequal'\n",
    "query = re.compile(pattern)\n",
    "query.findall(\"can there be freedom, without democracy? What equality, that's equally important\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now apply this technique to our corpus. Most of the code should like familiar by now, only line 8 needs a bit of explanation. `query.findall` returns a list with all the substrings that match the given regular expression. If there are more than `0` words found (line 8) then we add the path to `selected_paths`.\n",
    "\n",
    "Running the code may take a minute or two since we have to process the content of quite some files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = re.compile(r'\\bfreedom\\b|\\bdemocracy\\b') # define and compile the query\n",
    "selected_paths = [] # create empty variable where we'll store the results of the iteration\n",
    "for p in path_to_files: # iterate over all the files\n",
    "    txt = open(p).read() # open and read the file\n",
    "    txt_lower = txt.lower() # lowercase the text, save in new variable\n",
    "    results = query.findall(txt_lower) # query lowercased texts\n",
    "    if len(results) > 0: # check if query returned any results\n",
    "        selected_paths.append(p) # if True, add this path to selected_paths\n",
    "print(len(selected_paths)) # print number of collected files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python. an empty `list` (or dictionary) will evaluate to False, otherwise, if the list contains one or more items, the `if` condition returns True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code below will not print the message after if\n",
    "empty_list = []\n",
    "if empty_list:\n",
    "    print('condition is True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code below will print the message after if\n",
    "list_with_content = [1,2,3]\n",
    "if list_with_content:\n",
    "    print('condition is True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could therefore make the code in line 8 a bit more concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "query = re.compile(r'(?:\\bfreedom\\b|\\bdemocracy\\b|\\babolit)')\n",
    "selected_files = []\n",
    "for p in path_to_files:\n",
    "    txt = open(p).read()\n",
    "    txt_lower = txt.lower()\n",
    "    results = query.findall(txt_lower)\n",
    "    if results:\n",
    "        selected_files.append(p)\n",
    "print(len(selected_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Putting Everything Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By combining metadata and content criteria, you can navigate a corpus and select relevant documents. The code cell merges the previous examples.\n",
    "\n",
    "The crucial difference is line 20 where the `if` statements contains **two** conditions, both have to evaluate to `True` (since we use `and` operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True and True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True and False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True and True:\n",
    "    print('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True and False:\n",
    "    print('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def in_daterange(path,lower_b,upper_b):\n",
    "    newspaper_id, date, art_id = path.stem.split(\"_\")\n",
    "    year,month,day = int(date[:4]),int(date[4:6]),int(date[6:])\n",
    "    target_date = datetime(year,month,day)\n",
    "    return lower_b < target_date < upper_b\n",
    "\n",
    "lower_b = datetime(1830,1,1)\n",
    "upper_b = datetime(1831,1,1)\n",
    "\n",
    "query = re.compile(r'(?:\\bfreedom\\b|\\bdemocracy\\b)')\n",
    "\n",
    "selected_files = []\n",
    "for p in path_to_files:\n",
    "    txt = open(p).read()\n",
    "    txt_lower = txt.lower()\n",
    "    results = query.findall(txt_lower)\n",
    "    if results and in_daterange(p,lower_b,upper_b):\n",
    "        selected_files.append(p)\n",
    "print(len(selected_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Saving the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While selecting articles is useful for creating a specific subcorpus, you'd probably want to spend some time close-reading the results. Below we show how to export all the document to tabular data, an Excel file in this case. Part II of this course will have a closer look at working with tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def in_daterange(path,lower_b,upper_b):\n",
    "    newspaper_id, date, art_id = path.stem.split(\"_\")\n",
    "    year,month,day = int(date[:4]),int(date[4:6]),int(date[6:])\n",
    "    target_date = datetime(year,month,day)\n",
    "    return lower_b < target_date < upper_b\n",
    "\n",
    "lower_b = datetime(1830,1,1)\n",
    "upper_b = datetime(1831,1,1)\n",
    "\n",
    "query = re.compile(r'\\bfreedom\\b|\\bdemocracy\\b')\n",
    "\n",
    "rows = []\n",
    "for p in path_to_files:\n",
    "    txt = open(p).read()\n",
    "    txt_lower = txt.lower()\n",
    "    results = query.findall(txt_lower)\n",
    "    if results and in_daterange(p,lower_b,upper_b):\n",
    "        row = [p.stem,'; '.join(results),txt]\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_excel('working_data/corpus_hmd.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
