{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8: Exploring Tabular Data\n",
    "\n",
    "Using the example of metadata we have a closer look at working with CSV files (and tabular data more generally). We\n",
    "\n",
    "Precisely, in this lecture we cover:\n",
    "\n",
    "- load as .CSV as a pandas dataframe\n",
    "- selecting rows\n",
    "- manipulating values\n",
    "- sorting dataframes\n",
    "- plotting data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Introduction\n",
    "\n",
    "In this lecture we turn to working with (semi-)structured data. \n",
    "\n",
    "We referred to text as 'unstructured' because it Python initially reads the document as sequence of characters. Most of our effort went to wrangling 'raw' text to more meaningful representations, by for example detecting and counting words.\n",
    "\n",
    "In the coming lectures, we will insepct tabular or structured data. Tabular data consists of rows and columns. The rows represent individual records, which can be basically anything, a book, a measurement, a person. The columns are the atributes of these records. A common format of tabular data are spreadsheets, which you can open and edit with programs such as Microsoft Excel.\n",
    "\n",
    "Without further ado, let's look at a concrete example: structured metadata on British Library book corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 CSV Data: Metdata on the British Library Books Corpus\n",
    "\n",
    "\n",
    "The British Library Book corpus (BLB) contains work dating primarily from the 19th century. With rights cleared, this corpus is freely accessible to researchers and has proved a rich resource for previous and ongoing research projects. \n",
    "\n",
    "One problems with this corpus, however, is its composition. The selection criteria remain somewhat of a mystery: understanding the contours of the corpus is a non-trivial task and requires additional research at the level of corpus metadata.\n",
    "\n",
    "In this lecture we demonstrate how to explore the BLB metadata and get a better grip on this corpus. \n",
    "\n",
    "The data is available by following this link: `https://bl.iro.bl.uk/downloads/e1be1324-8b1a-4712-96a7-783ac209ddef?locale=en`. Let's inspect its basic format, before we explore the topic of dataframes in more detail.\n",
    "\n",
    "In the code below we use the `requests` library to download the data and  save it in the 'data`. We then print the first 300 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "link = 'https://bl.iro.bl.uk/downloads/e1be1324-8b1a-4712-96a7-783ac209ddef?locale=en'\n",
    "data = requests.get(link).text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you notice this data is actually just text, i.e. the metadata is initially just a string. We can confirm this by printing the data `type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But ho, wait. Didn't you tell us previousl we'd be working with structured data? Yes, but let's have a look at the data in its 'raw' format. \n",
    "\n",
    "What we printed earlier are the column names. You can observe how each name is separated by a comma. Also, spot the return character `\\n` this the end of the line. \n",
    "\n",
    "While initially just a text file, you notice that BLB has an implicit structure, determined by comma's (cell boundaries) and hard returns (row boundaries). This format are commonly refered to as CSV files, i.e. 'comma separated values' and you will encounter this format regularly when working with data in the Digital Humanities. \n",
    "\n",
    "The first row in a CSV file are commonly called the column headers and provide semantic information, i.e. what attribute of a record is recorded in this columns. \n",
    "\n",
    "The BL books data contains the following columns:\n",
    "\n",
    "```\n",
    "BL record ID,Type of resource,Name,Dates associated with name,Type of name,Role,All names,Title,Variant titles,Series title,Number within series,Country of publication,Place of publication,Publisher,Date of publication,Edition,Physical description,Dewey classification,BL shelfmark,Topics,Genre,Languages,Notes,BL record ID for physical resource\n",
    "```\n",
    "\n",
    "The first record looks as follow:\n",
    "\n",
    "```\n",
    "014602826,Monograph,\"Yearsley, Ann\",1753-1806,person,,\"More, Hannah, 1745-1833 [person] ; Yearsley, Ann, 1753-1806 [person]\",Poems on several occasions [With a prefatory letter by Hannah More.],,,,England,London,,1786,Fourth edition MANUSCRIPT note,,,Digital Store 11644.d.32,,,English,,003996603\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For exemple first column (`BL record ID`) records the identifier of a record. The identifier for the first record is `014602826`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Exploring CSV files as Pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While you could write a script to 'parse' these data, i.e. make implicit comma-separative structure explicit—remember text.split(`,`)?—there exist quite some tools to help you exploring and analysing tabular CSV data. \n",
    "\n",
    "In this course we will be working with Pandas, a popular tool that powers most of data science functionalities in Python. \n",
    "\n",
    "Below we import Pandas using the `pd` abbraviation. This is just for convenience, to save characters. If we want to call any tools from this library we just have to just `pd` instead of `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can read the csv file by just providing the link to the online document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://bl.iro.bl.uk/downloads/e1be1324-8b1a-4712-96a7-783ac209ddef?locale=en\",\n",
    "    index_col='BL record ID'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_csv()` takes a string as argument. This string can either represent a path (e.g. the location of a file on your local hard drive) or a URL (e.g. a link to an online repository). In our case we provide the URL as argument. We added one more name argument `index_col` where we specified\n",
    "\n",
    "We save the output of this function in a variable with the name `df`. The function returns a Pandas `DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe consists of rows and columns. The `.shape` attribute tells you exactly the 'dimension' of the datafarame, i.e. the number of rows and colums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, the BLB books corpus contains 52695 items. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect the column names you can print the `.columns` attribute attached to the DataFrame object `df`. This tells us the metadata attributes present in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `.head()` method to print the first rows. The code below prints the first three rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !! Explain !! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see `pd.read_csv` concerted the row text to a tabular format, identifying the rows and columns.\n",
    "So far we used the Pandas functionalities (the head method and attributes attached the dataframe) to explored the basic structure of the dataframe. However, its main strength lies in the many tools for accessing, manipulating and analysing content. We first discuss how to the access and retrieve content and then turn to manipulating information and deriving basic analytics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1 Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most straightforward method for access is via the index. In the code above we specified that `BL record ID` should be used as the index columns. This allows us the inspect the record related to this identifier. For example if we want to inspect the book with identifer `14602826` we pass this items as a string to `.loc`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[14602831]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax, as you'll notice, resembles those of dictionary, where the items between square brackets is the key via which we retrieve the corresponding value. You can read the above line in similar fashion: retrieve the record (value) with identifier (key) `14602831`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames also allow you to retrieve rows by their positional index using `.iloc()`. The code below prints the record at position 7 (i.e the 8th row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.loc` also allows for slicing (something that wasn't allows for dictionaries). The slice notation is similar to lists, where the colon separates the start and end positions. Note that the numbers in the code blow are not the positions but BL record identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[14602831:14602835]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course,`.iloc` also allow you to slice rows from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[200:205]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we access the content in the dataframe by specifying the rows we wanted to retrieve. But the Pandas dataframes enable you to retrieve by column, for example the one that records the date of publication for each book in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date of publication']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that columns belong to a different data type, namely `Series`. While a DataFrame always has two dimensions (rows and columns) a Series object only has one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['Date of publication'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date of publication'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning the columns itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date of publication']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output show the BL record identifier and the corresponding year of publication for that book. Please note the following about:\n",
    "- Firstly, some records have NaN (not a number) as date. This points to missing data, i.e. the book lacks a date of publication which can happen for many reasons. In Pandas the NaN is an instance of the float class. Run the code below to see if for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.loc[16289059,'Date of publication']\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Secondly, the returned column, comes with specification of its data type or `dtype`. On this case, the date of publication columns has `object` a type, which often that the columns contains information of different types. This may come a surprise, as we would expect dates or integers to appear in this column. If we look closer at the row with id `16289061` we observe that years are read as strings. In other words `Date of Publication` contains a mixture of string and float objects. Later in this tutorial we will show how to convert information in this columns to a integer indicating the year of publication, based in which we can plot time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.loc[16289061,'Date of publication']\n",
    "print(n,type(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, to select more than one column, you have to pass a list with column names (note the double opening and closing brackets in the statement below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Date of publication','Genre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the content of each column using other methods provided by the Pandas toolkit. When applied to a Series object, the `.unique()` methods show the set of the values in a columns (i.e. each unique value). This often helps with understanding and exploring the content of the CSV file. For example below we can inspect all the genres present in the BL books corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this information to select rows based on their genre, e.g. return all books categorized as 'Travel' literature. To accomplish this we need to construct a **mask** which is an array of boolen (True, False) values that express if the row matches our condition. Let's explore this with a toy-example.\n",
    "\n",
    "First we create a new, small, dataframe, which only records date of publication and genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy = pd.DataFrame([[1944,'Travel'],\n",
    "          [1943,'Periodical'],\n",
    "          [1946,'Travel'],\n",
    "          [1947,'Biography']], columns= ['Date of Publication','Genre'])\n",
    "df_toy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The we we create a mask using the `==` (is equal to) operator. In this case we want to retrieve row where the value in the Genre column is equal to `Travel`. This returns an array (more precisely a Pandas Series object) of boolean values: True when the recorded genre of a book matches the string `\"Travel\"`, False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy['Genre'] == \"Travel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save this mask in the `mask` variabel (note difference between `=`, value assignment, and `==` equals operator )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_toy['Genre'] == \"Travel\"\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can pass `mask` to loc, which returns those rows in the toy dataframe that contain travel literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking will return later on this course. For now it suffices to say that Pandas provides some useful functions for selecting subsets of a of dataframe. `.isin()` for example, is useful in scenarios where one wants to find multipe genres, for example `'Travel'` and `'Biography'`. This method takes a list of values as argument, and will return rows whose values appear in this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_toy['Genre'].isin([\"Travel\",\"Biography\"])\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we could have repeated the technique with  `==` operator and later combine the results, but `.isin()` provides a more elegant solution.\n",
    "\n",
    "Returning now to to the main example, the BLB corpus. The statements below demonstrate how masking enables you to explore these data by Genre. \n",
    "\n",
    "Note how we save the subsection of the original dataframe in a new variable `travel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['Genre'] == \"Travel\"\n",
    "travel = df[mask]\n",
    "travel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these steps, we can work on this specific set of rows and inspect the number of Travel books in the collection and their titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel['Title'].iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one more symbol we'd like to introduce before turning again to the leading example, the tilde or `~` which basically serves a negation: in the case below, it will return all rows except those having 'Travel' as their main Genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_toy['Genre'].isin([\"Travel\"])\n",
    "df_toy[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2 Manipulating dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already covered quite some ground in this lesson. At this point, you should have some basic understanding of how to open and explore Pandas DataFrames. In the part we go one step further demonstrate how you can change and manipulate information in these dataframes. We focus on the example of processing the dates of publication, converting the strings to integers that indicate the year of publication. This will help us later on with plotting and investigating trends over time in this corpus.\n",
    "\n",
    "First, let us inspect the values in this columns in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date of publication'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The messines of these data are quite common when working with heritage collections. Even though the data is structured, it still requires some processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date of publication'] > 1850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date of publication'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Date of publication'].isnull()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int('2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'2000-2019'.split('-')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int('2000-2019'.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_year = lambda x: int(x.lstrip('-').split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_year('2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_year('2000-2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'First year of pulication'] = df['Date of publication'].apply(first_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['First year of pulication'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['First year of pulication'].value_counts().sort_index().plot(kind='bar',figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['First year of pulication'].value_counts().sort_index()[1800:1900]#.plot(kind='bar',figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['First year of pulication'].value_counts().sort_index().loc[1800:1900]#.plot(kind='bar',figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['First year of pulication'].value_counts().sort_index().loc[1800:1900].plot(kind='bar',figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df['Genre'].value_counts()[:10].plot(kind='bar',figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['First year of pulication'] > 1850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['First year of pulication'] > 1850]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(1850,1860))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['First year of pulication'].isin(range(1950,1956))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['First year of pulication'].isin(range(1850,1860))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['First year of pulication'] > 1900) & (df['Languages'] != 'English')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['First year of pulication'] > 1900) & (df['Languages'] == 'German')]['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Title'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df[df.Languages=='English']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = text.CountVectorizer(min_df=10,stop_words='english')\n",
    "dtm = vectorizer.fit_transform(df_en['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape of document-term matrix: {dtm.shape}. '\n",
    "f'Number of tokens {dtm.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_df = pd.DataFrame(dtm.toarray(),index=df_en.index,columns=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_en.merge(dtm_df, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year = data.groupby('First year of pulication').sum()#['chicago'].sum()#.loc[1950:].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_counts = by_year.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_probs = by_year.divide(yearly_counts,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_probs['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_probs['woman'].loc[1800:1900].plot(kind='bar',figsize=(20,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
